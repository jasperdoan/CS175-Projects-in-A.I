CS 175 HW 1

                                                                                           
Glossary 


	Software 1.0

		explicit rules and instructions
		computer program follows this to solve a problem
		program's behavior is deterministic and predictable.
		program will only be as smart as the developer


	Software 2.0

		ML
		developers instead create software that learns to solve a problem on its own by analyzing patterns from data
		rather than rules, developers provide training (data examples)
		program will adjust internal parameters until it can make accurate prediction on data

			highly data driven
			programs behavior is not predicited
			more time spent on collecting and preparing data


	activation function

		applied to the output of a neuron in a neural network

		 determines whether the neuron should be "activated" or "fired" based on the input it receives.

		 	allows the network to learn complex, nonlinear relationships between the input and output data

		 		Without an activation function, the neural network would essentially be a linear model

		 		linear models can only model linear relationships between input features and the output variable, which can lead to underfitting of the data. 

		 	restricts range of nuerons value

		 		ex) classification, where the output is a probability value between 0 and 1



	ReLU (Rectified Linear Unit) activation function

		f(x) = max(0, x)

			if input is negative, output is 0
			if input is positive, output is input

			simple, computationally efficient
			does not suffer from the vanishing gradient problem.


	sigmoid activation function

		f(x) = 1 / (1 + exp(-x))

			curve is S-shaped and bounded between 0 and 1.

			often used in "classification" problems
			suffers heavily from vanishing gradient problem.

				function has a derivative that ranges between 0 and 0.25, which can cause the gradients to vanish quickly, leading to slower training.


	vanishing gradient problem

		gradients -> used to update the weights of the network

			can become very small as they propagate backwards through the layers of the network

			with many layers, gradients can become very small (close to 0) 
			with small gradients, the program will train/learn extremely slow

				as updates to the model will make little to no change 
				the gradient can become so small that the network effectively stops learning altogether.

				This can happen if the weight matrices have small values or if the activation functions used in the network have derivatives that are close to zero.

				especially problematic in networks with many layers or long-term dependencies between inputs and outputs.


	bias

		the level of systematic error or inaccuracy in a model's predictions.

		low bias

			model's predictions are generally accurate and close to the true values

		high bias

			model's predictions are consistently off target and have significant errors


	variance

		the level of random error or inconsistency in a model's predictions.

		low variance

			model's predictions are consistent and do not vary much between different training runs

		high variance

			model's predictions are highly sensitive to the specific training data used and can vary significantly between different training runs


	fitness

		ability for a model to capture patterns in the data

		underfit

			model is too simple and does not capture the patterns in the data well

			it performs poorly both on the training set and the test set. the model is unable to learn the patterns in the training data and therefore cannot generalize well to new data.

		overfit

			model that is too complex and captures noise and random fluctuations in the training data

			performs very well on the training set, but poorly on the test set.  the model has memorized the training data and is not able to generalize well to new data.


	precision

		the proportion correctly identified positives among all positive predictions made by the model.

			ex) spam emails

				Predicts 30 emails as spam, of which 10 are actually spam (true positives) and 20 are not spam (false positives).

				Precision = 10 / (10 + 20) = 0.33

		high precision

			when the model predicts a positive outcome, it is very likely to be correct.

				less legitimate emails are marked as spam

		low precision

			when the model predicts a positive outcome, it is less likely to be correct. 

				more legitimate emails are marked as spam


	recall 	

		performance metric = ratio of correct positive guesses to all positive instances

			ex) 78 offensive photos identified. 100 offensive photos were in the dataset. recall = 78/100

			recall measures the ability of a model to correctly identify all positive instances.
			
		high recall

			Indicates that the model is able to identify most of the positive instances
			
			useful when the goal is to identify all positive instances, even if that means accepting some false positives 

				false positives = incorrectly classified negative instances

		low recall 

			indicates that the model is missing a lot of positive cases


	Binary Outcomes

		True Positive (TP)

			true positive is a case where the model correctly identifies a positive instance. F

				The model correctly identifies a spam email as spam

		False Positive (FP)

			false positive is a case where the model incorrectly identifies a negative instance as positive. 

				The model incorrectly identifies a legitimate email as spam.

		True Negative (TN)

			true negative is a case where the model correctly identifies a negative instance.

				The model correctly identifies a legitimate email as legitmate

		False Negative (FN)

			A false negative is a case where the model incorrectly identifies a positive instance as negative

				The model incorrectly identifies a spam email as legitimate.


	multi-layer perceptron (MLP)

		type of artificial neural network

			commonly used in machine learning for both classification and regression

		typically consists of an input layer, one or more hidden layers, and an output layer. 

			The use of multiple hidden layers in an MLP allows it to learn complex and nonlinear relationships in the data

			MLP can capture hierarchical representations of the input data, with each layer learning more abstract and complex features than the previous layer.



Questions

	Q1.1 Bias vs Variance

		When a trained model is said to be “high bias”, is it underfit or overfit on the training set?

			[ ] overfit

			[x] underfit


	Q1.2

		Explain the concept of bias-variance tradeoff. Does it apply to deep neural networks (explain why or why not)?

			Typically, ML models would like to achieve low bias and low variance. However, when models try to decrease bias, there will be an increase in variance, and vice-versa.

			This applies to deep neural networks. Because these models deal with many inputs and have complex relations among data, models are especially suseptable to overfitting. overfitting is extremely low bias, but extremely high variance. So, caution must be taken to increase bias and lower variance.


	Q2 Software 2.0

		In your own words, explain how "Software 2.0" (Andrej Karpathy's term we mentioned in lecture), or training ML models, is different from Software 1.0, or traditional software engineering.

			Software 2.0 refers to a new approach to software development that relies on machine learning algorithms to learn from data and make decisions. It relies on training data to learn patterns and relationships that can be used to make predictions or decisions.

			Software 1.0 refers to the traditional approach to software development, where a human programmer writes code to implement a set of predefined rules and logic. These rules and logic are used to make predictions or decisions.

	Q3 Identifying Offensive Photos Case Study

		Q3.1 Identifying Offensive Photos Case Study

			What metric or metrics will you work to optimize as you work on the project?

				I would want to have a recall proportion be as close to 1.0 as possible. This is because the client states that every single offensive photo needs to be removed. We would not want any false negatives. 


		Q3.2 Dataset Split

			What are reasonable choices for splitting this data into training/validation/test sets?

				[ ] 20% to training, 20% to validation, 60% to test
				[ ] 98% to training, 1%  to validation, 1%  to test
				[x] 50% to training, 25% to validation, 25% to test
				[ ] 50% to training, 49% to validation, 1%  to test
				[ ] 20% to training, 40% to validation, 40% to test
				[x] 80% to training, 10% to validation, 10% to test

		Q3.3 Dataset Split Part 2

			What are reasonable choices for assigning examples that are labeled as offensive (“positive”) to training/validation/testing?

				[ ] All to the test dataset
				[x] According to the overall distribution
				[ ] Evenly across the validation and test datasets
				[ ] Evenly across training/validation/test, no matter what the overall distribution is

		Q3.4

			You came across a public dataset that another company put together for the same task. The data distribution in this dataset is similar but not the same: their forum is for anime fans, whereas yours is for software developers. Regardless, you want to add this data to your company's proprietary dataset.

			Select the best option for doing this:

				[ ] Add the new photos to the validation set only
				[ ] Add the new photos to the test set only
				[x] Add the new photos to the training set only
				[ ] Distribute the new photos into training/validation/testing sets following the same distribution as you selected in the previous question


	Q4

		What is the purpose of the activation function in a multi-layer perceptron?

			The use of multiple hidden layers in an MLP allows it to learn complex and nonlinear relationships in the data. However, it cannot learn non-linear patterns without a non-linear activation function. So, the MLP cannot be used to it's fullest potential.

	Q5 ReLU
	
		List two reasons to prefer the ReLU activation function over the sigmoid activation function.

			We prefer the ReLU activation fucntion because it is able to train faster than the sigmoid activation function. The sigmoid activation function has a derivative between 0 and 0.25 for all x, which would obviously cause slow training.

			Another reason we prefer ReLU is because max(0,z) is a simple operation for people to understand as well as to execute with code. it is also less likely to overflow compared to the sigmoid, which involves an exponential calculation.